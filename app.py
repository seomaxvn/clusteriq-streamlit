import streamlit as st
import pandas as pd
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.cluster import AgglomerativeClustering
import unicodedata
import re

st.set_page_config(page_title="ClusterIQ ‚Äì SEO Keyword Cluster Tool", layout="wide")
st.title("üîç ClusterIQ ‚Äì Keyword Clustering & Internal Linking")
st.markdown("Upload file CSV t·ª´ kh√≥a, m√¨nh s·∫Ω ph√¢n c·ª•m, g√°n vai tr√≤ Pillar/Cluster v√† t√≠nh ti·ªÅm nƒÉng SEO cho b·∫°n.")

uploaded_file = st.file_uploader("üì• Upload file .csv ch·ª©a c·ªôt 'Keyword'", type="csv")

def slugify(text):
    text = text.lower()
    text = unicodedata.normalize('NFD', text)
    text = text.encode('ascii', 'ignore').decode("utf-8")
    text = re.sub(r'[^\w\s-]', '', text)
    text = re.sub(r'[\s]+', '-', text)
    return '/' + text.strip('-')

def calculate_kos(volume, difficulty, intent):
    intent_weight = {
        "transactional": 1.5,
        "commercial": 1.2,
        "informational": 1.0,
        "navigational": 0.8
    }
    try: volume = float(volume)
    except: volume = 0.0
    try: difficulty = float(difficulty)
    except: difficulty = 0.0
    weight = intent_weight.get(str(intent).lower().strip(), 1.0)
    return (volume * weight) / (difficulty + 1)

def classify_kos(score):
    if score > 100: return "üî• R·∫•t ti·ªÅm nƒÉng"
    elif score > 50: return "‚úÖ Ti·ªÅm nƒÉng v·ª´a"
    elif score > 20: return "‚ö†Ô∏è Ti·ªÅm nƒÉng th·∫•p"
    else: return "‚ùå Kh√¥ng n√™n ∆∞u ti√™n"

if uploaded_file:
    df = pd.read_csv(uploaded_file)

    if "Primary Keyword" in df.columns:
        df["Keyword"] = df["Primary Keyword"]
    elif "Keyword" not in df.columns:
        st.error("‚ö†Ô∏è File c·∫ßn c√≥ c·ªôt 'Keyword' ho·∫∑c 'Primary Keyword'")
        st.stop()

    keywords = df["Keyword"].dropna().tolist()

    # TF-IDF clustering
    vectorizer = TfidfVectorizer(analyzer='word', ngram_range=(1,2), stop_words='english')
    X = vectorizer.fit_transform(keywords)
    clustering = AgglomerativeClustering(n_clusters=None, distance_threshold=1.2)
    df["Flexible Cluster ID"] = clustering.fit_predict(X.toarray())

    records = []
    for cluster_id, group in df.groupby("Flexible Cluster ID"):
        if len(group) < 2:
            continue

        pillar_row = group.loc[group["Keyword"].apply(len).idxmin()]
        pillar_kw = pillar_row["Keyword"]
        pillar_url = slugify(pillar_kw)

        for _, row in group.iterrows():
            role = "Pillar Page" if row["Keyword"] == pillar_kw else "Cluster Content"
            anchor = "" if role == "Pillar Page" else pillar_kw
            target = "" if role == "Pillar Page" else pillar_url
            kos = calculate_kos(row.get("Volume", 0), row.get("Keyword Difficulty", 0), row.get("Intent", "informational"))
            rating = classify_kos(kos)

            records.append({
                "Flexible Cluster ID": cluster_id,
                "Vai tr√≤": role,
                "Keyword": row["Keyword"],
                "Suggested URL": slugify(row["Keyword"]),
                "Li√™n k·∫øt ƒë·∫øn Pillar": target,
                "Anchor Text g·ª£i √Ω": anchor,
                "Intent": row.get("Intent", ""),
                "Volume": row.get("Volume", ""),
                "Difficulty": row.get("Keyword Difficulty", ""),
                "KOS": round(kos, 1),
                "M·ª©c ƒë·ªô ti·ªÅm nƒÉng": rating
            })

    result_df = pd.DataFrame(records)

    st.success("‚úÖ ƒê√£ x·ª≠ l√Ω xong!")
    st.dataframe(result_df)

    csv = result_df.to_csv(index=False).encode("utf-8")
    st.download_button("üì• T·∫£i file k·∫øt qu·∫£", data=csv, file_name="clusteriq_result.csv", mime="text/csv")
